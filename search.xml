<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[用 Docker 为 Trojan 客户端添加 HTTP 代理]]></title>
    <url>%2F2020%2F03%2F07%2Fhttp-proxy-for-trojan-by-docker%2F</url>
    <content type="text"><![CDATA[trojan 是近期热度很大的一个代理软件，本文不打算教大家怎么搭建 torjan，而是描述一下我如何解决使用 trojan 的时候遇到的一些问题。 我使用 trojan 的主要目的不是为了翻越那个伟大的长城，我笃信专业的事情找专业的人来干，花钱买机场比自己搭建来说省时省力。使用 trojan 主要是为了能够通过它提供的代理隧道来使用 openvpn。OpenVPN Connect 的客户端只支持 HTTP 代理，不支持 socks5，而 trojan 默认只支持 socks5 代理，所以必须做一层转换，将 socks5 代理协议转换成 HTTP 代理协议。 我用的办法是 privoxy，而为了使用的方便，我将 trojan 的客户端和 privoxy 打包进了 docker 镜像中。好处就是无论在什么环境，只要是执行一句 docker run 指令就可快速的拉起一个既支持 socks5 又支持 HTTP 协议的代理客户端。 而且现在这种新冠疫情下，大部分时间都是在家工作，家里大大小小的设备一堆，给每个设备都部署 trojan 非常麻烦。所以用 docker 在家里的 NAS 上部署一个 trojan 然后所有设备都共享这个代理，就方便了很多。 实现的方法很简单，我是在一个 ubuntu 的基础镜像之上安装了 privoxy 来提供 HTTP 代理服务，然后从 github 官方项目下载 最新版的 trojan 客户端。提供一个脚本来启动这两个应用，而在脚本中提供了可以通过环境变量来设置 trojan 的基本配置参数。 使用的方法很简单，可以通过下面的命令来快速的启动： 12345678docker run \ --name trojan-proxy \ -e REMOTE_ADDR="your host" \ -e PASSWORD="your password" \ -p trojan_port:1086 \ -p privoxy_port:1087 \ -d \ andyzhshg/trojan-privoxy:latest 其中参数环境变量 REMOTE_ADDR 用于指定 trojan 的服务地址，而 PASSWORD 用于指定服务的密码。 1086 端口是 socks5 代理的端口， 1087 是 HTTP 代理的端口，可以根据需要用 -p 指令映射成宿主机的端口。 基本上就是这么简单，如果你想指定更多的参数，我这里并没有提供相应的支持，但是你可以通过 fork 并修改我的项目来快速的得到你想要的结果： https://github.com/andyzhshg/trojan-privoxy docker hub 上的地址为： https://hub.docker.com/r/andyzhshg/trojan-privoxy]]></content>
      <categories>
        <category>泛技术</category>
      </categories>
      <tags>
        <tag>技术</tag>
        <tag>Docker</tag>
        <tag>VPN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cmake_dependent_option 详解]]></title>
    <url>%2F2019%2F12%2F12%2Fcmake_dependent_option%2F</url>
    <content type="text"><![CDATA[cmake_dependent_option 可以说是一个理解起来十分头疼的一条 cmake 命令了。我们先看看 cmake 的文档是怎么说的： Macro to provide an option dependent on other options. This macro presents an option to the user only if a set of other conditions are true. When the option is not presented a default value is used, but any value set by the user is preserved for when the option is presented again. Example invocation: 123&gt; CMAKE_DEPENDENT_OPTION(USE_FOO "Use Foo" ON&gt; "USE_BAR;NOT USE_ZOT" OFF)&gt; If USE_BAR is true and USE_ZOT is false, this provides an option called USE_FOO that defaults to ON. Otherwise, it sets USE_FOO to OFF. If the status of USE_BAR or USE_ZOT ever changes, any value for the USE_FOO option is saved so that when the option is re-enabled it retains its old value. 这段英文绕来绕去，越看越头疼，我就不按原文翻译了，只说一下我的理解。我先把这个命令的具体形式再重复一下： 1cmake_dependent_option(OPT_VAR "OPT_VAR_DES" DEF_VAL_1 "CONDITION_EXP" DEF_VAR_2) 这个命令带有 5 个参数: OPT_VAR OPT_VAR_DES DEF_VAL_1 CONDITION_EXP DEF_VAR_2 cmake_dependent_option的目的是要定义一个option，这个 option 就是 OPT_VAR，这个 option 的描述是 OPT_VAR_DES，这个 option 的默认值不是常量，而是 DEF_VAL_1 或者 DEF_VAL_2（DEF_VAL_1和DEF_VAL_2不同，但只能是ON或者OFF之一），具体是哪一个，取决于表达式 CONDITION_EXP，如果表达式 CONDITION_EXP 为 true，则默认值是 DEF_VAL_1，如果表达式 CONDITION_EXP 为 false，则默认值是 DEF_VAL_2。 如果我们把这个命令自己来实现一把的话，可能要需要下面这一大段代码： 1234567if(CONDITION_EXP) set(OPT_VAR_DEF DEF_VAL_1)else() set(OPT_VAR_DEF DEF_VAL_2)endif()option(OPT_VAR "OPT_VAR_DES" OPT_VAR_DEF) 使用 cmake_dependent_option的时候需要导入CMakeDependentOption这个模块，也就是需要包含下面的语句： 1include(CMakeDependentOption) 否则会出现类似 Unknown CMake command &quot;cmake_dependent_option&quot;.的报错。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>技术</tag>
        <tag>C++</tag>
        <tag>cmake</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用 AppleScript 一键自动处理选中的文本]]></title>
    <url>%2F2019%2F07%2F24%2Ftext-process-by-apple-script%2F</url>
    <content type="text"><![CDATA[这篇文章提到的方法是为了解决我在工作中遇到的一个实际问题，问题大概是这个样子的： 我的一个服务程序使用 golang 写的，其中的日志用了logrus 这个库，这个库本身很好用，但是我碰到一个问题 ，就是我的 log 中有一些数据本身就是以 json 格式输出的，但是 logrus 在日志文件中会默认的给输出中的双引号转义，最后看到的日志大概是这个样子的： 12time=&quot;2019-07-24T10:39:06Z&quot; level=info msg=&quot;[Out] &#123;\&quot;id\&quot;:257944,\&quot;type\&quot;:1,\&quot;timestamp\&quot;:1563964746233023125,\&quot;offer_id\&quot;:741807,\&quot;status\&quot;:&#123;\&quot;code\&quot;:0,\&quot;message\&quot;:\&quot;ok\&quot;&#125;,\&quot;data\&quot;:&#123;\&quot;symbol\&quot;:4,\&quot;topic\&quot;:\&quot;rest2engine_12_13\&quot;&#125;&#125;&quot;time=&quot;2019-07-24T10:39:06Z&quot; level=info msg=&quot;[Out] &#123;\&quot;id\&quot;:257945,\&quot;type\&quot;:3,\&quot;timestamp\&quot;:1563964746233044370,\&quot;trigger\&quot;:&#123;\&quot;id\&quot;:741807,\&quot;is_bid\&quot;:false,\&quot;amount\&quot;:\&quot;4380000000\&quot;,\&quot;clear\&quot;:true,\&quot;balance\&quot;:\&quot;0\&quot;,\&quot;data\&quot;:&#123;\&quot;symbol\&quot;:4,\&quot;topic\&quot;:\&quot;rest2engine_12_13\&quot;&#125;&#125;,\&quot;match\&quot;:[&#123;\&quot;id\&quot;:740840,\&quot;price\&quot;:\&quot;2074400000000\&quot;,\&quot;amount\&quot;:\&quot;1940000000\&quot;,\&quot;clear\&quot;:true,\&quot;balance\&quot;:\&quot;0\&quot;,\&quot;data\&quot;:&#123;\&quot;symbol\&quot;:4,\&quot;topic\&quot;:\&quot;rest2engine_12_13\&quot;&#125;&#125;,&#123;\&quot;id\&quot;:741724,\&quot;price\&quot;:\&quot;2074400000000\&quot;,\&quot;amount\&quot;:\&quot;2440000000\&quot;,\&quot;clear\&quot;:false,\&quot;balance\&quot;:\&quot;10735020000000000000000\&quot;,\&quot;data\&quot;:&#123;\&quot;symbol\&quot;:4,\&quot;topic\&quot;:\&quot;rest2engine_12_13\&quot;&#125;&#125;],\&quot;status\&quot;:&#123;\&quot;code\&quot;:0,\&quot;message\&quot;:\&quot;ok\&quot;&#125;&#125;&quot; 一般情况下，需要人肉去读这些日志的时候我会把 json 数据拷贝出来粘贴到一个可以格式化 json 的编辑器中。但是因为这个带了转义符号的数据已经不是合法的 json 了，所以 json 编辑器是无法直接处理的。 我已开始的做法是把数据拷贝到文本编辑器中，然后通过全局替换的方式把转义字符替换掉，即用 &quot; 替换 \&quot; 。这种方式其实在我这个场景工作的很好，只是比较麻烦，每次都要通过文本编辑器全局替换一次。 那么有没有更加有效率的方式呢？一开始我是想到可以自己写一个小程序专门的来处理这个替换过程，不过每次都需要调用小程序，比贴到文本编辑器全局替换也省不了时间。然后我就突然想到了是不是可以用 mac 的自动操作 Apple Script 来完成这件事，能想到这个是因为我之前在一篇文章里学到过通过 Apple Script 添加 VS Code 的右键菜单。 其实所谓的 Apple Script 基本上是不需要自己动手写代码的，只需要在图形化的编辑器里拖一拖选项就大致可以完成工作了。我的最终的成果就是可以在终端选中一段数据，然后通过右键选择我编写好的脚本动作，就把选中的文字做全局替换，然后将 json格式化，并且拷贝进剪贴板，查看的时候只需要在文本编辑器 cmd+v 将剪贴板的内容粘贴即可。比起之前的流程，简直是舒服了太多。 以下是 Apple Script 的制作过程： 打开 自动操作 程序 选 新建文稿，文稿类型为 快速操作 在搜索栏搜索 shell ，选择 运行 shell 脚本 组件，拖入工作区，并填入 sed &#39;s/\\\&quot;/\&quot;/g&#39; | /usr/local/bin/jq 作为脚本内容。 在搜索栏搜索 剪贴板，选择 拷贝至剪贴板 组件，拖入工作区。 保存脚本，比如我命名为 Logrus Trans 至此脚本就编写完成了，使用的效果大概是这样的 可能需要解释以下的是步骤 3 中的这段脚本： sed &#39;s/\\\&quot;/\&quot;/g&#39; | /usr/local/bin/jq 这是一个用管道串联起来的字符流处理，实际上 sed 之前是 AppleScript 传递过来的字符流，也就是我们选中的文本，sed &#39;s/\\\&quot;/\&quot;/g&#39; 会将文本中的 &quot; 替换成 \&quot; ，/usr/local/bin/jq 则将传递过来的文本中的 json 进行格式化。 步骤 4 会将步骤 3 的输出的文本拷贝到剪贴板中，这样在使用的时候直接用 cmd + v 粘贴到需要的地方就可以了。 这个例子是一个特例，其他人大概不会用到一模一样的情境，不过这里提供了一种思路，可以利用 AppleScript 快捷的处理繁复的工作。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>技术</tag>
        <tag>mac</tag>
        <tag>osx</tag>
        <tag>AppleScript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[利用 dns 负载均衡提高宽带多拨状态下的上行并发能力]]></title>
    <url>%2F2019%2F07%2F23%2Fdns-load-balance%2F</url>
    <content type="text"><![CDATA[终于如愿以偿的用上了软路由。体验到了飞一般的 $$ 速度，也体会到了单线多拨的好处，我电信宽带 100M 小水管 4 拨之后瞬时变成了大几百M的高速公路。 多拨的另外一个副产品就是一下子多了几个公网 IP，我想到有没有办法用上这几条多拨出来的线路，来提高家庭宽带的上行带宽呢？毕竟每条线路只有30M的上行带宽，在外边有多个终端连接进来时，可以并发的使用这些线路来提高负载能力。 koolshare 的改版 LEDE 中自带了一个软件中心，其中有一个很有用的插件 koolddns，可以用它来实现动态 dsn 绑定。并且在多拨的情况下，可以根据虚拟网卡来指定不同的 wan 口绑定到不同的域名。 我将我的四条线路分别绑定到 4 个不同的域名： 1234wan0 --&gt; a0.xxx.comwan1 --&gt; a1.xxx.comwan2 --&gt; a2.xxx.comwan3 --&gt; a3.xxx.com 这样我们就有了 4 个指向了不同 IP 的域名，而这 4 个 IP 都指向我们的路由器出口。在路由器后面我有一系列的机器，最主要的就是运行了各种网络服务的 NAS。 为了访问方便，我给重要的服务都申请了单独的子域名，比如： 1234git.xxx.comnas.xxx.comdb.xxx.com...... 以前没有多拨的时候我是直接通过 DDNS 把这些域名绑定到动态的宽带 IP 上，那么现在有了 4 条线路，该怎么绑定才可以让外边访问这些服务的时候访问不同的线路呢？ DNS的解析服务提供了给一个域名配置多条解析记录的功能 (我用的阿里云的解析服务，其他服务商可以自行查阅服务商的文档)。在配置了多条解析记录后，不同的终端访问该域名，域名服务商会将域名随机的解析到一个 IP 上，这就达到了一个负载均衡的效果。 koolddns 是不支持将多个 wan 口的 IP 设置到一个相同的域名的，所以我们上边为每个 wan 口设置了一个单独的域名。剩下的工作我们在域名解析服务上的后台来配置。 比如我要解析 git.xxx.com 这个域名，我需要在域名配置后台设置 4 条 cname 解析记录： 1234git --cname--&gt; a0.xxx.comgit --cname--&gt; a1.xxx.comgit --cname--&gt; a2.xxx.comgit --cname--&gt; a3.xxx.com 这样，当访问 git.xxx.com 的时候，会随机的解析到 a0-a3之中的一个 cname 域名，进而指向一个特定的 wan 口的 IP。 这种方式对于单一终端访问的带宽是没有提升的，因为一次只能连接一条线路，单条线路的带宽是固定的；但是对于多终端并发访问却是有提升的，因为不同的终端会分配不同的线路，多条线路之间的带宽是互不影响的。]]></content>
      <categories>
        <category>泛技术</category>
      </categories>
      <tags>
        <tag>技术</tag>
        <tag>DNS</tag>
        <tag>LEDE</tag>
        <tag>koolshare</tag>
        <tag>多拨</tag>
        <tag>DDNS</tag>
        <tag>OpenWRT</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[将 K8S 的 dashboard 语言强制设置为英文]]></title>
    <url>%2F2019%2F06%2F11%2Fk8s-dashboard-force-english%2F</url>
    <content type="text"><![CDATA[Kubernetes Web UI 默认的配置下语言会跟着浏览器的语言走，也就是说你的浏览器语言是中文的话，面板的语言默认也是中文，并且无法通过面板上的设置来选择语言。大多数时候当然是母语最适合用户，但是像 k8s 这种系统，网上查到的资料大都是英文的，所以反倒是看到对应的中文术语的时候会让人愣一下，反应下这个中文对应的英文术语是什么。所以我个人更倾向将开发工具都默认设置为英文，很多情况下这反倒是提高了我的工作效率。 既然 k8s 的面板默认没有提供语言的选择，有没有办法来切换呢？ 在网上搜索了一番，貌似都没有特别成熟或者方便的办法，下面这个网址算是一个解决办法： https://jimmysong.io/kubernetes-handbook/practice/dashboard-upgrade.html 12345678设置界面的语言我们看到现在 dashboard 的页面都已经被汉化了，当前支持英文、中文简体、中文繁体、日语，根据浏览器的语言自动切换的。如果想要强制设置 dashboard 中显示的语言，需要在 dahsboard 的 Deployment yaml 配置中增加如下配置：env: - name: ACCEPT_LANGUAGE value: english更简单的方式是，如果您使用的Chrome浏览器，则在浏览器中的配置中设置语言的顺序后刷新网页，dashboard将以您在Chrome中配置的首选语言显示。 可以说是两种方法：一种是部署 dashboard 的时候强制指定为英文，也就是说会无视用户浏览器的语言配置，默认都返回英文的页面；另一种是设置浏览器的语言，将浏览器的语言设置为英文即可。 两种方法都有弊端，前者我们必须有 k8s dashboard 的部署控制权，这在很多时候是不可能的，另外，这也剥夺了用户使用本地化语言的权力；后者的话会导致浏览器请求所有的网页都按照英文来请求，这也不是我们所期待的。 有没有办法能够只让 k8s dashboard 请求英文网页，而不影响其他网站呢，经过一番研究我找到了一个相对不算特别复杂的方法。 首先安装一个 chrome 插件：Locale Switcher。打开 k8s dashboard 可以通过点击插件图标来切换语言，选择英文即可。 不过这个插件默认是全局生效的，所以一但点击英文，所有的网站请求都会默认有限请求英文的网站。虽然可以通过点击中文来切换回来，比起到浏览器的语言设置里修改语言已经简单了许多。但是毕竟我们不想总是这样的手工控制语言切换。 其实chrome是可以指定插件可以生效的网站范围的，右键点击插件图标，选择管理扩展程序就会跳转到插件的管理页面，会看到一个条目是 有权访问的网站 ，在此条目下选择 在特定网站上 ，并在下面填写你的 k8s dashboard 个地址，形如 https://your-host:port/* (注意 *)。 这样将插件选择成英文后，再次刷新你的 k8s dashboard 页面时，语言就默认是英文了，而其他网站的语言设置却不受插件的影响，如果你嫌插件的图标占地方，甚至可以选择隐藏图标，因为大概率你以后不需要再点击这个图标了。 当然，这个方法也支持将其他网站的请求语言设置为不同的语言，不仅限于 k8s dashboard 。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>技术</tag>
        <tag>docker</tag>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一个用 etcd 作主备锁的细节问题]]></title>
    <url>%2F2019%2F05%2F29%2Fetcd-mutex-lock%2F</url>
    <content type="text"><![CDATA[etcd 越来越多的被应用在分布式系统中，最典型的一个应用场景就是作为分布式锁，用于在分布式系统中保证资源的独占。 通常的分布式的锁的应用场景有如下几种方式： 即用即申请，用完即释放，一般用于资源控制粒度比较细的系统，这种场景会频繁的调用 etcd 服务 还有一种就是先到先得，得到即长期占有，这种更多是用在主备系统的切换场景，如果占有锁的服务不发生异常，则不会主动与 etcd 交互。 本文主要讨论第2种场景中遇到的一个细节问题。 在主备切换的场景，我们希望服务一旦获取到锁，就不必主动的与 etcd 交互，而是专心的进行自己的本职工作。但是如果不主动跟 etcd 询问持有的锁的状态的话，我们又无法保证当前是确实持有锁的。正如下边的代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243package mainimport ( "context" "fmt" "time" "go.etcd.io/etcd/clientv3" "go.etcd.io/etcd/clientv3/concurrency")func main() &#123; client, errClient := clientv3.New(clientv3.Config&#123;Endpoints: []string&#123;"http://127.0.0.1:2379"&#125;, DialTimeout: 10 * time.Second&#125;) if errClient != nil &#123; fmt.Errorf("client create fail - %v", errClient) return &#125; session, errSession := concurrency.NewSession(client, concurrency.WithTTL(10)) if errSession != nil &#123; fmt.Errorf("create session fail - %v", errSession) return &#125; mutex := concurrency.NewMutex(session, "/lock") if mutex == nil &#123; fmt.Errorf("create mutex fail") return &#125; errMutex := mutex.Lock(context.TODO()) if errMutex != nil &#123; fmt.Errorf("lock fail - %v", errMutex) return &#125; fmt.Println("got lock, begin run work") go func() &#123; // do real work here &#125;() // prevent progress quit select &#123;&#125;&#125; 在 // do real work here 执行过程中，很可能我们的网络状态出现了问题，或者 etcd 服务出现问题导致程序已经跟网络断开，这时实际上锁很可能已经失效了。为了保证锁的有效性，我们可以在session的有效期内轮询锁的状态，但是这种做法很繁琐，也比较浪费资源。有没有更好的方式呢？ 好在 session 提供了一个 Done 方法，该方法返回一个 channel ， 一旦 session 结束，这个 channel 就会被写入内容，这样就给了我们一个简单地方法来监控锁的状态。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051package mainimport ( "context" "fmt" "time" "go.etcd.io/etcd/clientv3" "go.etcd.io/etcd/clientv3/concurrency")func main() &#123; client, errClient := clientv3.New(clientv3.Config&#123;Endpoints: []string&#123;"http://127.0.0.1:2379"&#125;, DialTimeout: 10 * time.Second&#125;) if errClient != nil &#123; fmt.Errorf("client create fail - %v", errClient) return &#125; session, errSession := concurrency.NewSession(client, concurrency.WithTTL(10)) if errSession != nil &#123; fmt.Errorf("create session fail - %v", errSession) return &#125; mutex := concurrency.NewMutex(session, "/lock") if mutex == nil &#123; fmt.Errorf("create mutex fail") return &#125; errMutex := mutex.Lock(context.TODO()) if errMutex != nil &#123; fmt.Errorf("lock fail - %v", errMutex) return &#125; fmt.Println("got lock, begin run work") go func() &#123; select &#123; case &lt;-session.Done(): // do what ever you want to process lock lost fmt.Println("lock lost") &#125; &#125;() go func() &#123; // do real work &#125;() // prevent progress quit select &#123;&#125;&#125; 如上边的代码所示，我们在一个 goroutine 中监听一个 &lt;-session.Done() 的 channel ，这样，一旦锁出现了问题，就会得到通知，这样就可以在这里进行一些锁丢失的善后工作，比如在这里停止所有的需要锁才能进行的工作，这样就不会出现锁已经失效，但是工作进程却全然不知的状况了。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>技术</tag>
        <tag>etcd</tag>
        <tag>go</tag>
        <tag>分布式</tag>
        <tag>锁</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一个让go的exec支持管道的小窍门]]></title>
    <url>%2F2019%2F05%2F16%2Fgo-exec-pipeline-support-trick%2F</url>
    <content type="text"><![CDATA[最近在一个 golang 开发的项目中需要用 exec 库调用外部 shell 命令，这个命令中用到了管道(pipline)。 由于是第一次用 exec 库，我想当然的把代码写成了这个样子： 1234567891011121314package mainimport "fmt"import "os/exec"func main() &#123; cmdStr := fmt.Sprintf("ls -l %s | head -n %d", ".", 10) cmd := exec.Command(cmdStr) if out, err := cmd.CombinedOutput(); err != nil &#123; fmt.Errorf("Error: %v\n", err) &#125; else &#123; fmt.Printf("Success: %s\n%s\n", cmdStr, out) &#125;&#125; 运行的时候发现这段代码是不能正确的工作的，经过在网上一通搜索后，发现网上给出的方案大致都是这个样子的：https://stackoverflow.com/questions/10781516/how-to-pipe-several-commands-in-go。这种方案确实是解决了问题，但是看起来却十分的复杂，我只是想调用一句 shell 命令而已，却要多写上十几行的 go 代码。 有没有更简单的方法呢？既然 go 自身处理不了，是否可以用 go 之外的工具来解决呢？ 然后就有了这个曲线救国的方案，exec 不再直接执行这个带有管道的命令，而是执行 sh 命令，然后我们的带有管道的 shell 命令作为参数传给 sh 来运行，类似于： 1sh -c "ls -l . | head -n 10" 至此，问题迎刃而解，比网上找到的方案简单了很多。落实到 go 代码大概就是下面的样子： 1234567891011121314package mainimport "fmt"import "os/exec"func main() &#123; cmdStr := fmt.Sprintf("ls -l %s | head -n %d", ".", 10) cmd := exec.Command("sh", "-c", cmdStr) if out, err := cmd.CombinedOutput(); err != nil &#123; fmt.Errorf("Error: %v\n", err) &#125; else &#123; fmt.Printf("Success: %s\n%s\n", cmdStr, out) &#125;&#125; 其实原则上，不局限于本题中管道的情形，这个方案还可以用在更多的需要调用复杂的 shell 命令的场合。]]></content>
      <categories>
        <category>go</category>
      </categories>
      <tags>
        <tag>技术</tag>
        <tag>go</tag>
        <tag>bash</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[etcd v2 v3 同时存在的问题]]></title>
    <url>%2F2019%2F04%2F02%2Fetcd-v2-v3%2F</url>
    <content type="text"><![CDATA[最近使用 etcd 时候遇到了一个问题，发现用 go 代码调用 clientv3 写进去的 key 和用 etcdctl 的 key 是不一样的，而且两边可以同时读写相同的 key， 但是知确实不相同的。 因为这个问题查了将近两个小时，最后发现，原来 etcd 默认情况下是 v2 和 v3 的客户端 API 共存的，而两个版本的 API 产生和查询的数据时隔离的。 用 etcd 的过程中看了不少的文章，结果恰恰我看的文章里都没有提到这一点，结果当了冤大头，浪费了这么多时间。 其实现在应该大部分人都是用 v3 版本的 API，etcdctl 默认却是 v2的 API。不知道是出于什么考虑没有把 v3 版本 API 作为 etcdctl 的默认 API 版本。 至于我会问到这个问题，也是因为我在开发的过程中想要用 etcdctl 来验证我的代码写进去的数据是否正确，如果我没有用 etcdctl 来读 go 客户端写进去的数据的话，也就不会有这个问题了。如果想要让 etcdctl 默认用 v3 版的 API，可用在使用 etcdctl 之前，设置版本环境变量： 12export ETCDCTL_API=3etcdctl ... 如果不想每次使用 etcdctl 是都设置，可以在 .bashrc 或者 .bash_profile 加入该语句： 1export ETCDCTL_API=3]]></content>
      <categories>
        <category>泛技术</category>
      </categories>
      <tags>
        <tag>技术</tag>
        <tag>etcd</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mac的终端用ss做代理]]></title>
    <url>%2F2019%2F02%2F15%2Fmac-term-ss%2F</url>
    <content type="text"><![CDATA[最近在研究golang，go提供了一个很好用的工具就是go get。go get本身不得不说是一个伟大的设计，极大地减轻了我们做包管理的负担，这个对于主要做C++的我的感受尤为明显。 但是在我们这个国家里，因为某些你懂得原因，顺利的用go get却成了一件很困难的事。之前写过一篇文章介绍如何让git走SS代理，但是go get还是与git的情况不是完全一致的。 google了一圈之后，我总结了一个更加通用的方法。 理论上这个方法可以让所有的终端的命令通过SS提供的socks5代理来访问网络。 方法很简单，就是在需要用代理的时候运行如下的命令： 1export all_proxy=socks5://127.0.0.1:1080 其中socks5://127.0.0.1:1080是SS提供的socks5代理服务的监听地址，可以在Shadowsocks的高级设置下找到。 如果想减少每次打开执行导入命令的麻烦，可以将导入语句加入到~/.bash_profile中。 参考：https://github.com/mrdulin/blog/issues/18 https://studygolang.com/articles/9490 https://github.com/golang/go/wiki/GoGetProxyConfig]]></content>
      <categories>
        <category>泛技术</category>
      </categories>
      <tags>
        <tag>技术</tag>
        <tag>go</tag>
        <tag>git</tag>
        <tag>ss</tag>
        <tag>mac</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[罗技鼠标滚轮失灵的处理办法]]></title>
    <url>%2F2018%2F12%2F24%2Flogintech-mouse-whele-not-working%2F</url>
    <content type="text"><![CDATA[我一直在用罗技的一款鼠标 M720 Triathlon , 这款鼠标因为多了几个自定义键，可以设置对应mac触摸板的手势，我一直用的很开心。不过自从上周升级完 macOS Mojave 10.14.2 后突然发现鼠标的滚轮不能用了，包括滚动以及滚轮的左右波动，还有哪两颗自定义键。 因为升级系统的当天也同时升级了罗技的鼠标管理软件Logitech Options，我一度以为是罗技软件的问题，所以我尝试了降级Logitech Options，依然无果。最后将Logitech Options卸载掉了之后发现滚轮可以用了，但是自定义键依然不能用。 就这样别扭着用了好几天，并同时尝试联系罗技的客服，然而问题提交几天根本没有人回复，也是服了这客服了。后来实在是不心甘，有常识寻找解决办法，终于在罗技自己的论坛找到了遇到同样问题的用户提出的问题和解决办法： 点击左上角苹果图标 点击系统偏好设置 点击安全性与隐私 点击隐私标签页 点击左侧的辅助功能 选中Logitech Options Deamon(如果是灰掉的不能点就先点击左下角的锁图标解锁) 这时就发现滚轮生效了，而且可以通过Logitech Options来设置自定义键的功能了。 虽然可能是苹果系统升级引起的问题，但是问题出了这么久罗技官方也没有升级软件或者给出暂时解决办法，也是很不负责任。希望这篇文章能够被搜索引擎检索到，让碰到同样问题的人少些麻烦。 罗技，You are welcome! 很高兴帮你做客服… 参考：论坛原贴]]></content>
      <categories>
        <category>泛技术</category>
      </categories>
      <tags>
        <tag>数码</tag>
        <tag>泛技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用安装在 Docker 中的 jenkins 运行 Docker 任务]]></title>
    <url>%2F2018%2F11%2F27%2Frun-docker-by-jenkins-in-docker%2F</url>
    <content type="text"><![CDATA[题目有点绕，我先尝试翻译成人话——首先安装一个 jenkins，这个 jenkins 是通过 docker 安装的，然后要用这个 jenkins 来运行自动化的项目，项目中会用到 docker 命令。而这种工作场景，采用默认的配置，是完成不了的。 缘起故事的缘起是这个博客，他是基于 Github Pages 的，使用的过程就是用 MarkDown 写文章，通过 HEXO 系统来构建，然后 push 到 github 上。 整体的流程实际上也不算复杂，但是作为一个程序员，总觉得会有更加智能和省事的方法（实际上就是不折腾不舒服而已）。 所以我想构建一个系统，来达到博客的自动构建和发布的效果。鉴于这部分跟主题的关系不是特别大，还是不再赘述博客的事了，也许以后会写一篇博客自动构建的文章，这里就不展开了。 思路提到自动构建，很自然的想到了jenkins；然后恰好我有一台群晖的NAS，上边可以跑Docker，所以又很自然的想到了通过Docker来安装jenkins；有了jenkins，当然还要通过jenkins来运行自动化的任务，运行任务最简单且对NAS系统侵入最小的方式是通过Docker运行任务。 问题上面的思路看似很顺畅，但是认真思考一下会发现，因为jenkins本身是运行在一个容器里的，所以我们在创建任务的时候给出的脚本或命令，都是在这个容器内运行的，这就出现了一个问题，这个容器内部是没有docker环境的，所以执行不了docker命令，也就是说，必须想办法来让这个容器内部可以执行docker任务。 方案经过一番搜索之后，我找到了了这篇文章：在（Docker里的）Jenkins里运行Docker。 最终我选择了文中提到的DooD（Docker-outside-of-Docker）方案。 也就是所想办法让jenkins容器可以执行宿主机上的docker命令。 因为需要给予jenkins用户sudo权限，然而官方的镜像jenkins默认是没有sudo用户权限的，所以我在官方镜像的基础上新建了一个镜像，默认给jenkins用户sudo权限。 andyzhshg/jenkins 改动的内容如下： 12345678910FROM jenkins:2.60.3MAINTAINER andyzhshg &lt;andyzhshg@gmail.com&gt;USER rootRUN apt-get update \ &amp;&amp; apt-get install -y sudo \ &amp;&amp; rm -rf /var/lib/apt/lists/*RUN echo "jenkins ALL=NOPASSWD: ALL" &gt;&gt; /etc/sudoersUSER jenkins 运行这个镜像的容器很简单： 12345docker run -d \ -v /var/run/docker.sock:/var/run/docker.sock \ -v $(which docker):/usr/bin/docker -p 8080:8080 \ andyzhshg/jenkins 需要重点关注带有 -v 参数的两行： 第1行是将宿主机的 /var/run/docker.sock 映射到容器中，这样在容器中运行的 docker 命令，就会在宿主机上来执行。 第2行是将宿主机的 docker 程序映射进容器中，这样本身没有安装 docker 的 jenkins 容器就可以执行 docker 命令了（事实上容器里是没有运行 docker 的服务的，我们只是用这个映射进容器的 docker 来作为客户端发送docker的指令到 /var/run/docker.sock 而已，而 /var/run/docker.sock 已经被链接到宿主机了）。 至此，我们的 jenkins 就准备就绪了。 当然，通常情况下我们还需要把jenkins自身的数据目录链接到宿主机的目录中，以保证容器被销毁后还能够再启动新的数据而数据可以得到保留，这些可以参考jenkins官方镜像的说明。 比如在docker run加上 -v your_jenkins_data_path:/var/jenkins_home参数。 初始化jenkins的配置之后，我们就可以在jenkins上来新建一个自动化的构建项目了，比如我的blog自动构建项目的自动化脚本大概就是这个样子： 12345678910echo "new blogs posted, begin auto build."# 从gitlab拉取内容更新，构建并推送到github pagessudo docker run --rm -v /volume1/docker/blog/key/:/root/.ssh -v /volume1/docker/blog/up4dev:/blog andyzhshg/hexo# 推送一份内容原文到github做备份sudo docker run --rm -v /volume1/docker/blog/key/:/root/.ssh -v /volume1/docker/blog/up4dev:/blog andyzhshg/hexo /blog/backup2github.sh echo "auto build done." 这虽然是一个特例化的应用场景，但是其他的项目也大同小异，只要准备好docker的镜像，然后再jenkins执行docker run就可以了。 需要注意的是，这里的docker run一定是要以sudo权限运行的。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>技术</tag>
        <tag>docker</tag>
        <tag>ci</tag>
        <tag>jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spdlog 简介]]></title>
    <url>%2F2018%2F07%2F27%2Fspdlog-tutorial%2F</url>
    <content type="text"><![CDATA[spdlog是一个速度快，只有头文件(header only)的C++日志库。安装和使用非常简单，而功能也比较强大，因为其简单易用轻量，可以用作我们日常开发的日志库。 项目的地址：https://github.com/gabime/spdlog 文档地址：https://github.com/gabime/spdlog/wiki 项目主页上介绍了该库的一系列特色： 快，非常快，性能是设计的首要目标。 只有头文件 (header only)，拷贝即用 基于fmt实现的丰富的格式调用 自定义格式 条件日志输出 多线程/单线程日志输出 丰富的日志输出目标 日志文件自动切割(Rotating) 按日分割日志文件 控制台输出(支持着色) 系统日志(syslog) windows debuger (OutputDebugString(..)) 方便的自定义扩展 过滤-可以再运行时或者编译时修改过滤级别 使用的例子可以参考项目的实例或者文档，非常明了。]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>技术</tag>
        <tag>C++</tag>
        <tag>算法</tag>
        <tag>库</tag>
        <tag>后端</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[EOS 代码分析 [1] —— AppBase]]></title>
    <url>%2F2018%2F06%2F26%2Feos-code-read-1-appbase%2F</url>
    <content type="text"><![CDATA[EOSIO/appbase,如项目介绍所说—— The AppBase library provides a basic framework for building applications from a set of plugins. AppBase manages the plugin life-cycle and ensures that all plugins are configured, initialized, started, and shutdown in the proper order. 是一个从一系列插件构建应用的基本框架。 EOS的大多应用都是基于这个框架来构建的。 AppBase是独立于EOS项目的一个独立项目，可以单独的编译，我们也可以利用这个框架构建自己的应用。 为了方便描述，我fork了一份代码，并在这个fork项目上添加了我阅读过程中的注释，这个fork的项目在这里： andyzhshg/appbase 下文的介绍均基于AppBase提供的示例程序为基础进行说明，这个示例程序实现了一个net_plugin，这个net_plugin又有一个依赖项chain_plugin。这基本展示了AppBase使用中的方方面面。 0. 基本使用流程一个基于AppBase的程序的基本使用流程如下： 注册插件，register_plugin 初始化，initialize 启动，startup 进入事件监听等待，exec 程序退出，shutdown。 基本上就是这么简单，AppBase本身提供了一个基础进程环境，来使得用户的代码可以以插件的形式集成进来。 下面我们逐一解析一下这些步骤 1. 注册插件application::register_plugin是一个模板函数，模板参数是要注册的插件的类型。 该函数首先通过插件的名称查找该插件是否已经注册过，如果注册过则直接返回，不会重复注册。插件名的名称是根据插件的类型推导得来的。 如果没有注册过，则new一个插件的对象，并将其记录进plugins这个列表中。 调用插件自身的register_dependencies来注册插件自身的依赖，插件的依赖也是插件。 2. 初始化从application::initialize函数的实现可以看到实际的初始化工作是在application::initialize_impl完成的。 其完成的主要工作是完成程序配置项的设置和根据配置项做初始化。 配置项的初始化部分，首先是调用插件的配置项设置 ，然后才是程序自身的配置项设置。配置项的处理是使用boost::program_options完成的。 配置项处理完成后，首先是根据配置进行application自身的初始化处理，然后是根据配置项进行插件的初始化处理。 3. 启动application::startup的过程很简单，就是逐一调用插件的startup函数，并处理异常。 因为application::startup本身不进行任何应用逻辑的处理，所有的应用逻辑都是插件来完成的，所以我们只要看一下插件是如何完成startup的。 我们发现，用户并不需要实现startup函数，而是实现一个plugin_requires和plugin_startup。而事实上如果我们观察示例程序，发现其并没有实现plugin_requires函数，这个函数事实上是实现了的，由一个APPBASE_PLUGIN_REQUIRES宏来实现，这个宏极大的简化了声明依赖的过程，只需要提供一个依赖的插件的类型的列表即可，我的代码注释中有对这个宏的简单解释，你也可是尝试展开这个宏。经过这个宏的简化，实际上必须有用户自己完成的只有plugin_startup这个函数了，这里给用户一个机会来完成插件自身在启动前要完成的工作。 需要注意的是，插件的调用顺序是与注册的顺序相同的。 4. 进入事件等待application::exec函数启动一个boost::asio::io_service并监听了几个信号：SIGINT / SIGTERM / SIGPIPE，并阻塞在io_serv-&gt;run(); 这行代码，当进程收到这几个信号中的一个的时候，阻塞函数返回，并进入shutdown函数。 5. 程序退出观察示例代码我们发现并没有显式调用application::shutdown函数，实际上这是由上一步骤中监听的事件来触发的，也就是类似CTRL+C这样的键盘时间或者kill之类的命令触发的。 在这个函数中，会逐一的调用插件的shutdown函数，时间上就是用户自己编写的plugin_shutdown函数。 需要注意的是，shutdown中调用插件的顺序是与startup的时候的顺序相反的，也就是注册的相反的顺序。 总结综合上述的流程，我们发现基于AppBase编写一个程序主要的工作就是编写插件，而完成一个插件的流程就是如下简单几个步骤： 从appbase::plugin派生 用APPBASE_PLUGIN_REQUIRES宏来声明插件的依赖 实现plugin_initialize 实现plugin_startup 实现plugin_shutdown 对于AppBase的实现细节我的fork项目andyzhshg/appbase里的注释解释的比较详细了。其中有一部分是关于method和channel的，AppBase本身的示例并没有演示用法，这篇文章没有解释，也许后续研究EOS的过程中我会回头解释这个设计。]]></content>
      <categories>
        <category>区块链</category>
      </categories>
      <tags>
        <tag>区块链</tag>
        <tag>技术</tag>
        <tag>C++</tag>
        <tag>EOS</tag>
        <tag>智能合约</tag>
        <tag>插件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[EOS 代码分析 [0]]]></title>
    <url>%2F2018%2F06%2F26%2Feos-code-read-0%2F</url>
    <content type="text"><![CDATA[去年就开了一个坑打算分析比特币的源码，结果到现在还没有动手，理由能找到不少，但归根结底还是因为懒。比特币源码分析这个坑不打算弃，因为毕竟代码已经读的差不多了，就差写文章了，如果我争气一点的话会找时间把这个坑填上。 最近都在研究EOS，又手痒打算写一系列EOS源码分析的文章，这算是个开端。为了避免出现去年那样的挖坑不填的情况，我打算这次边看代码边写文章，文章可能会很杂很细碎，只要起到一个记录的作用就好了。如果以后有余力，再写一写系统性的分析文章。 FLAG立在这里了，开始执行。 以下是已经完成的文章列表，我随着写作的进度逐步添加： EOS 代码分析 [1] —— AppBase 我从eos的主项目clone了一份代码，写这篇文章的时候的最新release版本是v1.0.6，后续如果有重要的更改可能会merge主项目的代码，本系列文章讨论的代码均会指向我的这个fork的项目： andyzhshg/eos 这篇开头的文章先简单介绍一下代码的基本结构，我大致介绍一下代码根目录的下重要的文件和目录： 文件或目录 说明 programs 重要的二进制程序的入口代码，每个子目录都对应一个二进制程序，比如服务主程序 nodeos，钱包程序 cleos 等 libraries 重要组件库代码，可以说核心的实现代码大都在这个路径下 contracts 合约程序代码，包含重要的系统合约和一些示例合约 plugins 插件目录，eos 的架构本身就是基于一套插件体系构建起来，功能都是以插件的形式集成进来的，所以这个目录非常重要 eosio_build.sh 构建脚本，通过该脚本可以自动获取依赖构建项目]]></content>
      <categories>
        <category>区块链</category>
      </categories>
      <tags>
        <tag>区块链</tag>
        <tag>技术</tag>
        <tag>C++</tag>
        <tag>EOS</tag>
        <tag>智能合约</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[群晖 Let's Encrypt 泛域名证书自动更新]]></title>
    <url>%2F2018%2F05%2F29%2Fsynology-ssl-wildcard-cert-update%2F</url>
    <content type="text"><![CDATA[去年曾经写过一篇文章介绍如何在群晖的 NAS 通过 acme 协议更新 Let’s Encrypt 的 HTTPS 证书。最近突然发现acme协议版本更新，开始支持泛域名(wildcard)，也就是说，可以申请一个类似*.domain.com的单一证书，就可以适配abc.domain.com，xyz.domain.com这类的子域名，而不需要单独为每个子域名申请证书了。 Neilpang/acme.sh 工具很快就支持新的协议了，我这篇文章就是在这个工具的基础上，实现泛域名的自动更新。为了减少复杂度，我编写了一个一键更新的懒人脚本，来帮助不愿意了解原理的同学快速部署。 1. 准备工作因为我介绍的方法是一键替换群晖的默认证书，所以，为了防止意外，最好保证你的证书列表里只有一条记录，即默认证书那一条。实际上因为支持了泛域名证书，基本上这一条记录就足够用了（当然，如果你要管理多个域名，可能本文的方法并不实用）。所以开始工作前你的证书列表大概应该是这个样子： 2. 下载一键更新脚本这是一键脚本的项目地址：andyzhshg/syno-acme。 如果你对项目本身不感兴趣，可以直接下载打包好的工具：syno-acme v0.2.0。 可以通过 File Station 将下载的工具上传到NAS的任意目录下，并解压。 解压后大概是这个样子： 3. 配置脚本参数编辑脚本的配置文件config: 如图所示，需要编辑的几个字段我用蓝框标记出来了。 首先是DOMAIN，也就是你的域名。 然后是DNS的类型，根据服务商的不同，DNS类型各不相同，比如阿里云（dns_ali），Dnspod（dns_dp），Godaddy（dns_gd）等。 最后要根据不同的服务商配置服务上提供的授权密钥等信息，比如我的域名服务商是阿里云，我需要编辑Ali_Key和Ali_Secret字段，字段的内容需要到域名服务商的管理后台来查看，因为不同的服务商的查看方式不同，请大家根据自己的实际情况去查找吧。 需要指出的是，我给出的配置文件模板并没有给出所有acme.sh支持的域名服务商，大家可以参照 https://github.com/Neilpang/acme.sh/tree/master/dnsapi来添加自己的配置。一般情况下，这个页面每个文件对应一个域名服务商，比如dns_ali.sh就是对应阿里云，文件名去掉.sh扩展名就是DNS类型，比如阿里云的DNS类型就是dns_ali。打开对应文件， 一般都可以在文件的头部找到需要设置的授权信息对应的密钥，比如阿里云的授权密钥所在的位置如下图所示： config模板中没有的服务商，请大家自行完善。 [^2018.05.31]: 针对评论区同学提出的 Linode 的 API 生效时间的问题，增加了一个配置参数DNS_SLEEP，出现类似问题的话可以通过修改增大这个参数来解决。 4. 配置定时任务i. 查找脚本路径在 File Station 中定位到下载的一键脚本的目录，查看该脚本的绝对路径： 复制完整的绝对路径到剪贴板。 ii. 创建定时任务打开 控制面板 / 任务计划 / 新增 / 计划的任务 / 用户自定义的脚本： 设置任务名称和操作用户，需要注意的是这里一定要选择root： 设置计划的时间和周期，这里只支持按月或者年重复，我们只能取按月重复才能满足 Let’s Encrypt 至少3个月更新一次的要求： 设置执行脚本，这里我们将脚本的输出重定向到了一个log.txt的文件中，以方便后期查看脚本的执行情况： 上图红框中的脚本命令为(注意没有换行)： 1/volume1/nas_share/certs/syno-acme/cert-up.sh update &gt;&gt; /volume1/nas_share/certs/syno-acme/log.txt 2&gt;&amp;1 具体的路径是步骤 i中复制的路径。 iii. 试运行脚本可以在新建的任务上点击右键立即执行任务： 这样脚本就会运行，自动更新证书，并重启web服务器加载新的脚本。以后，NAS会每隔一个月执行一次该脚本，自动更新证书。 iv. 回滚脚本里提供了回滚命令，可以通过ssh登录到nas，定位到对应目录，执行如下命令回滚证书目录到备份的状态： 1/volume1/nas_share/certs/syno-acme/cert-up.sh revert 总结这个一键脚本的特点是最小限度的触碰系统文件，仅/usr/syno/etc/certificate/_archive目录会被更改。acme.sh工具随用随时下载，保持最新，用完即删除，不占用磁盘空间。 这基本就是本文的全部了，如果大家使用中遇到问题，可以在这里留言或者到 https://github.com/andyzhshg/syno-acme/issues 提issue。 [^参考1]: Synology NAS Guide[^参考2]: 群晖 Let’s Encrypt 证书的自动更新]]></content>
      <categories>
        <category>泛技术</category>
      </categories>
      <tags>
        <tag>NAS</tag>
        <tag>HTTPS</tag>
        <tag>Let&#39;s Encrypt</tag>
        <tag>群晖</tag>
        <tag>泛域名</tag>
        <tag>acme</tag>
        <tag>Synology</tag>
        <tag>SSL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何让git命令通过ss拉取github代码]]></title>
    <url>%2F2018%2F05%2F14%2Fgithub-use-ss%2F</url>
    <content type="text"><![CDATA[github 还没有被墙，但是 github 很慢（至少我家的北京电信宽带下情况是这样）。终于忍受不了github 10~50 KB 的下载速度，我在网上找了下设置代理的方法，让 git 命令可以通过 ss 代理拉取 github 的代码。 我们从 clone 一个全新的项目开始。 这里其实是针对特定项目设置代理的方法，其实也可以设置全局的代理，这样每个项目就跟不设置代理时一样操作就可以了，我不想每个项目都走代理（因为我有一些不托管在 github 的项目），所以才会分开设置。设置全局代理的方法，可以参考我在文末给出的参考链接。 1. 构建项目目录一般情况下，我们克隆一个项目都是直接通过 git clone 命令，像这样： 1git clone git@github.com:YourName/YourRepo.git 或者这样 1git clone https://github.com/YourName/YourRepo.git git clone命令会创建一个目录并将项目的代码数据拉取到这个目录中，这样的话我们还没有机会给项目设置代理，就已经开始从网络获取数据了。所以这里我将这个步骤做了一下分解。 我们通过下边的步骤来初始化项目 123456789# 首先创建一个空的项目目录mkdir YourRepocd YourRepo# 初始化git环境git init# 添加远端分支git remote add master git@github.com:YourName/YourRepo.git# 或者git remote add master https://github.com/YourName/YourRepo.git 这样我们就初始化好了一个项目，下一步我们将为这个项目设置 ss 代理。 2. 设置 ss 代理设置代理的方式很简单就一条命令： 1git config http.proxy 'socks5://127.0.0.1:1080' 上面对应的是通过http协议的方法，对应git协议，通过下边的命令： 1git config core.gitProxy 'socks5://127.0.0.1:1080' 3. 拉取代码1git pull 到这里基本上就讲完了，如果是一个已经存在的项目，之前没有走代理，现在想走代理，那么其实更简单，略过第1步，从第2步开始即可。 如果是新建项目，执行完 git pull 后可能发现目录是空的，这是因为项目此时没有在任何一个指定的分支下，只要执行形如 git checkout master 命令来把项目切到一个分支即可。 参考： Git搭配shadowsocks使用代理访问github [^update 2019.02.15]: 这篇文章 提到的方法可能是mac上一个更加便捷且普适的方法。]]></content>
      <categories>
        <category>泛技术</category>
      </categories>
      <tags>
        <tag>技术</tag>
        <tag>git</tag>
        <tag>ss</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在群晖 DS716+II 上安装 VMM(Virtual Machine Manager)]]></title>
    <url>%2F2018%2F05%2F10%2Finstall-vmm-on-ds716%2F</url>
    <content type="text"><![CDATA[我有一台群晖的NAS，型号是DS 716+II。一直都知道群晖的高端型号都是支持虚拟化的，但是在群晖的官网上查Virtual Machine Manager的支持机型，我的716+II是不支持的。不过因为这个机器是支持Docker的，所以不支持虚拟机就不支持吧，反正大部分我想要的功能用Docker都实现，这机器的赛扬处理器用来跑虚拟机本身也不会跑的很舒服。 不过最近在研究如何自动化的把DS Photo上的照片再备份一份到Google Photos，毕竟Google Photos的体验还是很不错的。 网上查到有人说了一种曲线救国的方案：用VMM虚拟一个Windows，然后在Windows里安装Google的Windows版的客户端。虽然蛋疼，但也是一种曲线救国的方案，于是我开始研究怎么在我的机器上安装VMM。然后发现居然非常简单，直接下载一个916+(其他x86平台的安装包应该也都可以)的VMM的安装包，手动安装即可… 我做一下雷锋，直接把916+的VMM安装包的下载页面贴这里，免去大家自己找的麻烦： https://www.synology.cn/zh-cn/support/download/DS916+#packages 在这个页面里搜索Virtual Machine Manager即可找到下载链接。至于怎么手动安装，怎么使用VMM，我就不详细说了。]]></content>
      <categories>
        <category>泛技术</category>
      </categories>
      <tags>
        <tag>技术</tag>
        <tag>NAS</tag>
        <tag>虚拟机</tag>
        <tag>VMM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[管理多个github账号的 ssh key]]></title>
    <url>%2F2018%2F05%2F05%2Fgit-multi-ssh-key%2F</url>
    <content type="text"><![CDATA[我们大多时候是通过ssh key的方式来进行github代码库的权限管理，如何生成一个ssh key以及如何在github设置网络上有各类的说明，不是本文的重点。本文要解决的是在一个机器上管理多个账号的方法。 出于各种原因，有些人会有多个github账号，比如一个个人账号，一个工作账号。而github是不允许两个账号出现相同的SSH KEY的。那么问题来了，我们为了方便，往往都是用ss-keygen命令，一路默认参数在~/.ssh目录下生成一对名为id_rsa和id_rsa.pub的密钥，然后把id_rsa.pub贴到github的SSH and GPG keys设置中去。 如何生成一个新的密钥给另一个账号，并且在使用的过程中尽量减少麻烦呢，我这里给出一种相对简便的方法。 1. 生成一对命名的ssh key首先生成一对新的ssh key，依然是用ssh-keygen命令，只是这次不用默认的参数。 123456789101112131415161718192021ssh-keygenGenerating public/private rsa key pair.Enter file in which to save the key (/YourHomeDir/.ssh/id_rsa):/YourHomeDir/.ssh/account1Enter passphrase (empty for no passphrase):Enter same passphrase again:Your identification has been saved in /YourHomeDir/.ssh/account1.Your public key has been saved in /YourHomeDir/.ssh/account1.pub.The key fingerprint is:SHA256:...The key's randomart image is:+---[RSA 2048]----+| . .o+.oo ||. oo. ..ooo o ||o+o.+o .oo.+ = ||=+ .o.Eo... = . ||+ . S. o . || . o . o || B * || o X * || .o B.. |+----[SHA256]-----+ 需要关注的是上边命令中的第3行，我们输入了/YourHomeDir/.ssh/account1，也就是我们所希望的ssh密钥的名字以及路径，其他步骤基本都一样，一路默认参数回车就可以了。这是我们在/YourHomeDir/.ssh/路径下生成了一对名为account1和account1.pub的新秘钥。 一定要注意新秘钥的命名，不要覆盖掉旧的秘钥造成不必要的麻烦。 2. 更改本地的SSH配置123cd ~/.sshtouch configvim config 上面的命令在ssh配置目录创建(如果不存在)一个config文件，并用vim打开编辑。通过vim编辑加入如下配置： 1234# 配置示例1Host xxxx HostName github.com IdentityFile ~/.ssh/account1 其中第1行中的xxxx是一个代替github.com的名字，你可以用一个自己比较容易记得域名，比如我就比较喜欢这样： 1234# 配置示例2Host my-github-name.github.com HostName github.com IdentityFile ~/.ssh/account1 其中my-github-name是对应我生成的这个ssh key的github账号的名字。 3. 将新生成的ssh key加到github账号配置下将第一步生成的秘钥对中的account1.pub的内加入github账号的SSH and GPG keys设置项中。因为是一个全新的秘钥，自是不会再出现添加不进去的问题。 4. 克隆新的项目一般情况下，我们是通过如下的方式克隆一个项目： 1git clone git@github.com:your-account/your-prj.git 我们需要对这个语句中的域名部分做一下修改： 12# 对应配置示例1git clone git@xxxx:your-account/your-prj.git 12# 对应配置示例2git clone git@my-github-name.github.com:your-account/your-prj.git 这时，我们就是通过新的ssh key来clone的代码，在此之后的操作就没有区别了，一切按照之前的使用习惯即可，无论是pull还是push代码等操作都使用新的ssh key来进行了。 这里补充说一个可能跟ssh key的关系不大，但是跟多账号有关的问题，是关于commit代码的账号的设置的。如果默认不处理，提交代码的时候提交信息中的用户和邮箱信息是用户设置的全局账户的信息，当时应该是这样设置的： 123&gt; git config --global user.name "You Name"&gt; git config --global user.email name@example.com&gt; &gt; 我们往往是要给不同项目设置不同的提交信息，毕竟你不想把公司的邮箱带到私人项目的提交记录中去。可以通过下边的方式文每个项目单独设置提交账户信息： 1234&gt; cd YourRepoPath&gt; git config user.name "You Name"&gt; git config user.email name@example.com&gt; &gt; 其实很简单，就是去掉--global参数。 我的第一个账号是通过默认方式添加的，所以如果没有用自定义域名添加的项目都是使用的默认的密钥即id_rsa，为了使用方便，可以让自己使用最频繁(或者是项目最多的账户)使用这个默认配置。 如果你有更多的账号，通过上边的方法来生成更多的ssh key并通过自定义域名的方式对不同账号的项目进行区分即可。 本方法同样适用于gitlab的多账号情境。]]></content>
      <categories>
        <category>泛技术</category>
      </categories>
      <tags>
        <tag>技术</tag>
        <tag>git</tag>
        <tag>github</tag>
        <tag>ssh</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[群晖 Let's Encrypt 证书的自动更新]]></title>
    <url>%2F2017%2F09%2F11%2Fsynology-ssl-cert-update%2F</url>
    <content type="text"><![CDATA[去年入手了一个群晖的 NAS DS716+II，这玩意儿可以说是垂涎了好久，最后忍不住诱惑，终于是入手了。选了716+II这个盘位少但价格不便宜的家伙说白了就是为了一件事——docker。有了docker，可以说就有了无限的可能性，可以随便折腾，不用担心犯错误把NAS的主系统给搞乱了。 不过今天这篇文章我不打算介绍NAS，也不打算说怎么在上边用docker，我只想说说在这个上边怎么使用Let’s Encrypt的证书，以及怎么自动更新证书。 [2018.05] 这篇文章提供的方案已经过时，请参考我的另一篇文章：群晖 Let’s Encrypt 泛域名证书自动更新 如果说你幸福的生活在一个运营商没有封80端口的国度，那么这篇文章你就不必往下看了，因为群晖的证书管理本身就内置了Let’s Encrypt的证书管理方式。我之所以写这篇文章，是因为我家的网络是没有开放80端口的，所以群晖自带的管理工具永远都是告诉你“无法连接到 Let&#39;s Encrypt。请确认域名有效。” 好在Let’s Encrypt提供了acme协议的认证方式，可以在没有80端口的情形下来签发和更新证书。 感谢伟大的GitHub以及无私的开发者们，所有的工具基本上都已经被开发了出来。 Neilpang/acme.sh 这个项目基本上就是我们用到的所有的工具了。 如果你是一个动手能力强的人，那么我在告诉你一下群晖的证书的保存位置/usr/syno/etc/certificate/的话，余下的工作你就应该可以自己搞定了。 下面就开始介绍具体的步骤： 1. 下载并安装acme.sh1234# 登入NASssh -p your_port your_name@your_host# 下载并安装acme.sh工具curl https://get.acme.sh | sh 2. 修改配置文件，填入你在指定域名提供商的授权token12345678# 进入到配置文件所在目录cd ~/.acme.sh/dnsapi# 打开阿里云的配置文件，其他提供商可以自行修改对应的配置文件vi dns_ali.sh# 修改如下两行配置为你自己的token，注意要去掉前面的#号# #Ali_Key="LTqIA87hOKdjevsf5"# #Ali_Secret="0p5EYueFNq501xnCPzKNbx6K51qPH2"# 保存并退出vi 不同的提供商的token的形式和配置方式可能会有不同，需要你到域名管理的后台自己去获取。 3. 准备用于存放安装后的证书的目录1234567# 新建一个存放所有证书的根目录mkdir cert_save_pathcd cert_save_path# 为每个子域名创建对应的mkdir sub1.example.commkdir sub2.example.com# ... 4. 生成证书12345# 首先加载acme.sh的环境变量source ~/.acme.sh/acme.sh.env# 执行证书获取命令，我这里的dns_ali是对应阿里云的，其他供应商可以查阅acme的文档acme.sh --issue --dns dns_ali -d sub1.example.comacme.sh --issue --dns dns_ali -d sub2.example.com 5. 安装证书12345678acme.sh --installcert -d sub1.example.com \ --certpath /cert_save_path/sub1.example.com/cert.pem \ --key-file /cert_save_path/sub1.example.com/privkey.pem \ --fullchain-file /cert_save_path/sub1.example.com/fullchain.pemacme.sh --installcert -d sub2.example.com \ --certpath /cert_save_path/sub2.example.com/cert.pem \ --key-file /cert_save_path/sub2.example.com/privkey.pem \ --fullchain-file /cert_save_path/sub2.example.com/fullchain.pem 其实这里的安装是指的acme将获取的证书安装到之前建立好的目录，并没有安装到NAS自己的证书管理下边。 6. NAS证书安装控制面板 -&gt; 安全性 -&gt; 证书 -&gt; 新增 -&gt; 添加新证书 -&gt; 导入证书(描述那里填完整的子域名) -&gt; 导入证书文件(私钥为privkey 证书为cert.pem 中间证书为fullchain.pem) 这一步将我们从Let’s Encrypt获取的证书安装到了NAS，我们发现有效期是三个月，如果你能够接受三个月走一遍上边的流程，那么到这里就可以结束了，如果想把这个过程自动化起来，请接着看下边的流程。 7. 证书更新命令因为Let’s Encrypt的证书的有效期只有三个月，所有我们必须至少每三个月执行一次更性操作，以防止证书过期。 12345678910acme.sh/acme.sh --renew --force --dns dns_ali -d sub1.example.comacme.sh/acme.sh --installcert -d sub1.example.com \ --certpath /cert_save_path/sub1.example.com/cert.pem \ --key-file /cert_save_path/sub1.example.com/privkey.pem \ --fullchain-file /cert_save_path/sub1.example.com/fullchain.pemacme.sh/acme.sh --renew --force --dns dns_ali -d sub2.example.comacme.sh/acme.sh --installcert -d sub2.example.com \ --certpath /cert_save_path/sub2.example.com/cert.pem \ --key-file /cert_save_path/sub2.example.com/privkey.pem \ --fullchain-file /cert_save_path/sub2.example.com/fullchain.pem 执行上边的命令，会从Let’s Encrypt更新证书，并安装到指定的位置。 8. 拷贝证书脚本这一步我认为一定是有其他方法来做的，但是因为搞不明白群晖NAS的证书存放逻辑，暂时就想了这么一个折中的办法。 通过观察可以发现，所有证书相关的配置都是在路径/usr/syno/etc/certificate下的，证书存放的具体位置是/usr/syno/etc/certificate/_archive，该目录下的内容形如： 12zFLdC DEFAULT dXWIy3 h94Uuq IhSb6T INFO kGn0Zn uTv2EL vY1OEs WE3xYE 其中INFO的内容是一个JSON文件，记录了每个证书的存放位置和应用的范围，DEFAULT记录了哪一个是默认的证书，其他的目录则是存放一个一个的子域名的证书。 通过观察INFO的内容我们可以发现目录名和域名的对应关系，我编写了一个python脚本来分析这个对应关系以及将前文的证书拷贝到对应的位置，脚本名称为update.py. 12345678910111213141516171819202122232425262728293031323334353637383940# update.pyimport jsonimport osimport shutilSRC_BASE_PATH = '/cert_save_path' # 这是步骤3里创建的目录DES_BASE_PATH = '/usr/syno/etc/certificate'ARC_BASE_PATH = '/usr/syno/etc/certificate/_archive'# [archive_key: (domain_name, destination_path)]keys = &#123;&#125;cfg_str = open('/usr/syno/etc/certificate/_archive/INFO').read()cfg = json.loads(cfg_str)# name to keyfor k in cfg: for service in cfg[k]['services']: name = service['display_name'] if name.find('up4dev.com') &lt; 0: continue keys[k] = &#123;'name' : name, 'arc_path' : '%s/%s' %(ARC_BASE_PATH, k), 'des_path' : [], 'src_path': '%s/%s' %(SRC_BASE_PATH, name)&#125; # des_path = '%s/%s/%s' %(CERT_BASE_PATH, service['subscriber'], service['service']) # print name, des_pathfor k in cfg: for service in cfg[k]['services']: des_path = '%s/%s/%s' %(DES_BASE_PATH, service['subscriber'], service['service']) if os.path.exists(des_path): keys[k]['des_path'].append(des_path)for key in keys: print keys[key] shutil.copy2(keys[key]['src_path'] + '/cert.pem', keys[key]['arc_path'] + '/cert.pem') shutil.copy2(keys[key]['src_path'] + '/privkey.pem', keys[key]['arc_path'] + '/privkey.pem') shutil.copy2(keys[key]['src_path'] + '/fullchain.pem', keys[key]['arc_path'] + '/fullchain.pem') for des in keys[key]['des_path']: shutil.copy2(keys[key]['arc_path'] + '/cert.pem', des + '/cert.pem') shutil.copy2(keys[key]['arc_path'] + '/privkey.pem', des + '/privkey.pem') shutil.copy2(keys[key]['arc_path'] + '/fullchain.pem', des + '/fullchain.pem') 9. 重启web服务12# 我选用的是nginx作为Web服务，如果选择Apache则执行Apache的重启命令/usr/syno/etc/rc.sysv/nginx.sh reload 10. 自动化脚本我们将8，9，10三个步骤的操作串起来，做成一个自动化脚本，保存为auto_update.sh 123456789101112131415161718# 更新并安装acme.sh/acme.sh --renew --force --dns dns_ali -d sub1.example.comacme.sh/acme.sh --installcert -d sub1.example.com \ --certpath /cert_save_path/sub1.example.com/cert.pem \ --key-file /cert_save_path/sub1.example.com/privkey.pem \ --fullchain-file /cert_save_path/sub1.example.com/fullchain.pemacme.sh/acme.sh --renew --force --dns dns_ali -d sub2.example.comacme.sh/acme.sh --installcert -d sub2.example.com \ --certpath /cert_save_path/sub2.example.com/cert.pem \ --key-file /cert_save_path/sub2.example.com/privkey.pem \ --fullchain-file /cert_save_path/sub2.example.com/fullchain.pem# 拷贝到NAS的证书路径python update.py# 重启Web服务/usr/syno/etc/rc.sysv/nginx.sh reload 11. 设置定时任务控制面板 -&gt; 任务计划 -&gt; 新增 -&gt; 计划的任务 -&gt; 用户定义的脚本 -&gt; 计划(设置成每月执行一次) -&gt; 任务设置(用户定义的脚本中填入步骤10的脚本的完整路径) [^2018.05.09]: Let’s Encrypt 已经支持wildcard类型的证书，可能已经有比本文更好的方法了，待我研究之后再写一篇文章。 [^2018.05.30]: 泛域名的更新方法我已经另写了另一篇文章，大家可以参考：群晖 Let’s Encrypt 泛域名证书自动更新 参考 forum.51nb.com: 群晖安装并自动续期Let’s Encrypt SSL证书 Neilpang/acme.sh 说明 ]]></content>
      <categories>
        <category>泛技术</category>
      </categories>
      <tags>
        <tag>NAS</tag>
        <tag>HTTPS</tag>
        <tag>Let&#39;s Encrypt</tag>
        <tag>群晖</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git commit 时指定时间和作者等信息]]></title>
    <url>%2F2017%2F06%2F12%2Fgit-commit-info-specify%2F</url>
    <content type="text"><![CDATA[最近遇到了这么一个问题，需要在提交代码的时候指定提交的时间和作者等信息，而不是当前用户和当前时间提交（不要问我为什么，就是有这么个需求）。 经过一通的搜索查找资料，终于找到一个还算是比较方便的办法。 12345GIT_AUTHOR_DATE=&quot;2017-06-01 12:33:08&quot; \ GIT_COMMITTER_DATE=&quot;2017-06-01 12:33:08&quot; \ git commit . \ --author=&quot;author name &lt;author@email.com&gt;&quot; \ -m&quot;some commit message&quot; 是不是很简单。]]></content>
      <categories>
        <category>泛技术</category>
      </categories>
      <tags>
        <tag>技术</tag>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[比特币源码分析写作计划]]></title>
    <url>%2F2017%2F01%2F09%2Fbitcoin-code-review-plan%2F</url>
    <content type="text"><![CDATA[2017年说来就来，回顾去年一年似乎也没有干多少正经的事情。 因为现在的工作和兴趣都在区块链这边，这新的一年的重心应该都会在区块链上，所以就有了这个计划。目的主要是敦促自己坚持完成一件事情，另外也对学习的过程有一定的记录。如果万一能够给来这里的读者一定的帮助，也算是意外的收获了。 计划中的主题会有如下的部分： 代码的版本，编译，基础组织结构 交易 区块链 挖矿 网络 写作的过程中，这些主题会有一定的调整，但是比特币相关细节的各个部分都应该会涵盖在内。 这个计划挂在这里，主要是要督促自己不要懈怠，具体执行的结果，随后拭目以待吧。]]></content>
      <categories>
        <category>区块链</category>
      </categories>
      <tags>
        <tag>区块链</tag>
        <tag>比特币</tag>
        <tag>BitCoin</tag>
        <tag>技术</tag>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++11的智能指针(2) shared_ptr]]></title>
    <url>%2F2016%2F10%2F19%2Fcpp11-shared_ptr%2F</url>
    <content type="text"><![CDATA[C++11新引入了几种智能指针：unique_ptr，shared_ptr和weak_ptr，而原来的auto_ptr被弃用。 我会写几篇文章分别来介绍这几种智能指针的用法，本篇主要介绍shared_ptr。 shared_ptr可以说是我们最常规意义上理解的智能指针了，区别于unique_ptr，share_ptr有拷贝构造函数和赋值操作符，每当shared_ptr多出一个拷贝，所有拷贝的引用计数都会增加。 shared_ptr的常规用法12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152// example1.cpp#include &lt;iostream&gt;#include &lt;memory&gt;class Test &#123;public: Test(int tag) : _tag(tag) &#123; std::cout &lt;&lt; "Test::Test() " &lt;&lt; _tag &lt;&lt; std::endl; &#125; ~Test() &#123; std::cout &lt;&lt; "Test::~Test() " &lt;&lt; _tag &lt;&lt; std::endl; &#125; void test() &#123; std::cout &lt;&lt; "Test::test() " &lt;&lt; _tag &lt;&lt; std::endl; &#125;private: int _tag;&#125;;int main() &#123; std::shared_ptr&lt;Test&gt; p1(new Test(1)); p1-&gt;test(); std::cout &lt;&lt; "p1:" &lt;&lt; p1.use_count() &lt;&lt; std::endl; std::cout &lt;&lt; "----------------" &lt;&lt; std::endl; std::shared_ptr&lt;Test&gt; p2 = std::make_shared&lt;Test&gt;(2); p2-&gt;test(); std::cout &lt;&lt; "p2:" &lt;&lt; p2.use_count() &lt;&lt; std::endl; std::cout &lt;&lt; "----------------" &lt;&lt; std::endl; std::shared_ptr&lt;Test&gt; p3 = p1; p3-&gt;test(); std::cout &lt;&lt; "p1:" &lt;&lt; p1.use_count() &lt;&lt; std::endl; std::cout &lt;&lt; "p3:" &lt;&lt; p3.use_count() &lt;&lt; std::endl; std::cout &lt;&lt; "----------------" &lt;&lt; std::endl; p1.reset(); std::cout &lt;&lt; "p1:" &lt;&lt; p1.use_count() &lt;&lt; std::endl; std::cout &lt;&lt; "p3:" &lt;&lt; p3.use_count() &lt;&lt; std::endl; std::cout &lt;&lt; "----------------" &lt;&lt; std::endl; p2 = p3; p2-&gt;test(); std::cout &lt;&lt; "p2:" &lt;&lt; p2.use_count() &lt;&lt; std::endl; std::cout &lt;&lt; "p3:" &lt;&lt; p3.use_count() &lt;&lt; std::endl; std::cout &lt;&lt; "----------------" &lt;&lt; std::endl; return 0;&#125; 编译 1g++ -o example1 -std=c++11 example1.cpp 运行结果 123456789101112131415161718192021Test::Test() 1 Test::test() 1p1:1 (1)----------------Test::Test() 2Test::test() 2p2:1 (2)----------------Test::test() 1p1:2p3:2 (3)----------------p1:0p3:1 (4)----------------Test::~Test() 2Test::test() 1p2:2p3:2 (5)----------------Test::~Test() 1 (6) (1) 展示了用shared_ptr的构造函数来生成一个shared_ptr对象，并且我们看到他的引用计数现在是1。 (2) 展示了用make_shared来生成一个shared_ptr，可以看到，这里我们终于彻底告别了new，是不是感觉有点暗爽。 (3) 展示了shared_ptr的赋值操作，我们看到，赋值之后，p1和p3的引用计数都增加到了2。 (4) reset操作使得p1变为空的，所以它的引用计数为0，而p3的引用计数则减少到了1，此时的p1和p3已经完全不是一回事了。 (5) p2 = p3的操作使得p2原来指向的对象被释放，所以我们首先看到一条析构函数的输出。然后我们看到p2 p3的的引用计数都变成了2。 (6) 程序退出的时候，很自然的，所有的智能指针都出了作用域，所以最后一条析构调用被输出。 类型转换假设我们两个类1234567891011121314151617181920212223242526272829303132333435363738394041#include &lt;iostream&gt;#include &lt;memory&gt;class Base &#123;public: Base() &#123; std::cout &lt;&lt; "Base::Base()" &lt;&lt; std::endl; &#125; ~Base() &#123; std::cout &lt;&lt; "Base::~Base()" &lt;&lt; std::endl; &#125; virtual void test() &#123; std::cout &lt;&lt; "Base::test()" &lt;&lt; std::endl; &#125;&#125;;class Derived : public Base &#123;public: Derived() &#123; std::cout &lt;&lt; "Derived::Derived()" &lt;&lt; std::endl; &#125; ~Derived() &#123; std::cout &lt;&lt; "Derived::~Derived()" &lt;&lt; std::endl; &#125; virtual void test() &#123; std::cout &lt;&lt; "Derived::test()" &lt;&lt; std::endl; &#125;&#125;;int main() &#123; std::shared_ptr&lt;Base&gt; pb = std::make_shared&lt;Base&gt;(); std::shared_ptr&lt;Derived&gt; pd = std::make_shared&lt;Derived&gt;(); std::cout &lt;&lt; "pb.use_count() " &lt;&lt; pb.use_count() &lt;&lt; std::endl; std::cout &lt;&lt; "pd.use_count() " &lt;&lt; pd.use_count() &lt;&lt; std::endl; pb = static_cast&lt;Base&gt;(pd); std::cout &lt;&lt; "pb.use_count() " &lt;&lt; pb.use_count() &lt;&lt; std::endl; std::cout &lt;&lt; "pd.use_count() " &lt;&lt; pd.use_count() &lt;&lt; std::endl; pb-&gt;test(); return 0;&#125; 用static_cast, dynamic_cast, const_cast是无法用在不同的shared_ptr之上的。 自己实现一个shared_ptr12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061//shared_ptr.hnamespace up4dev &#123; template&lt;typename T&gt; class shared_ptr &#123; public: shared_ptr() : _p(nullptr), _c(nullptr)&#123; &#125; ~shared_ptr() &#123; reset(); &#125; shared_ptr(T* p) : _p(p), _c(new int(1)) &#123; &#125; shared_ptr(const shared_ptr&amp; sp) &#123; reset(); _p = sp._p; _c = sp._c; *_c += 1; &#125; shared_ptr&amp; operator=(const shared_ptr&amp; sp) &#123; reset(); _p = sp._p; _c = sp._c; *_c += 1; return *this; &#125; T* get() &#123; return _p; &#125; T* operator-&gt;() &#123; return _p; &#125; void reset() &#123; if (_c) &#123; *_c -= 1; if (*_c == 0) &#123; delete _p; delete _c; &#125; _p = nullptr; _c = nullptr; &#125; &#125; int use_count() &#123; return _c ? *_c : 0; &#125; private: T* _p; int* _c; &#125;;&#125; 对前文的测试用例稍加修改，用新写的shared_ptr来替换标准库的实现 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152//example3.cpp#include &lt;iostream&gt;#include "shared_ptr.h"class Test &#123;public: Test(int tag) : _tag(tag) &#123; std::cout &lt;&lt; "Test::Test() " &lt;&lt; _tag &lt;&lt; std::endl; &#125; ~Test() &#123; std::cout &lt;&lt; "Test::~Test() " &lt;&lt; _tag &lt;&lt; std::endl; &#125; void test() &#123; std::cout &lt;&lt; "Test::test() " &lt;&lt; _tag &lt;&lt; std::endl; &#125;private: int _tag;&#125;;int main() &#123; up4dev::shared_ptr&lt;Test&gt; p1(new Test(1)); p1-&gt;test(); std::cout &lt;&lt; "p1:" &lt;&lt; p1.use_count() &lt;&lt; std::endl; std::cout &lt;&lt; "----------------" &lt;&lt; std::endl; up4dev::shared_ptr&lt;Test&gt; p2 = up4dev::shared_ptr&lt;Test&gt;(new Test(2)); p2-&gt;test(); std::cout &lt;&lt; "p2:" &lt;&lt; p2.use_count() &lt;&lt; std::endl; std::cout &lt;&lt; "----------------" &lt;&lt; std::endl; up4dev::shared_ptr&lt;Test&gt; p3 = p1; p3-&gt;test(); std::cout &lt;&lt; "p1:" &lt;&lt; p1.use_count() &lt;&lt; std::endl; std::cout &lt;&lt; "p3:" &lt;&lt; p3.use_count() &lt;&lt; std::endl; std::cout &lt;&lt; "----------------" &lt;&lt; std::endl; p1.reset(); std::cout &lt;&lt; "p1:" &lt;&lt; p1.use_count() &lt;&lt; std::endl; std::cout &lt;&lt; "p3:" &lt;&lt; p3.use_count() &lt;&lt; std::endl; std::cout &lt;&lt; "----------------" &lt;&lt; std::endl; p2 = p3; p2-&gt;test(); std::cout &lt;&lt; "p2:" &lt;&lt; p2.use_count() &lt;&lt; std::endl; std::cout &lt;&lt; "p3:" &lt;&lt; p3.use_count() &lt;&lt; std::endl; std::cout &lt;&lt; "----------------" &lt;&lt; std::endl; return 0;&#125; 编译 1g++ -o example3 -std=c++11 example3.cpp 运行结果 123456789101112131415161718192021Test::Test() 1Test::test() 1p1:1----------------Test::Test() 2Test::test() 2p2:1----------------Test::test() 1p1:2p3:2----------------p1:0p3:1----------------Test::~Test() 2Test::test() 1p2:2p3:2----------------Test::~Test() 1 C++11的智能指针系列文章 C++11的智能指针(1) unique_ptr C++11的智能指针(2) shared_ptr]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>技术</tag>
        <tag>C++</tag>
        <tag>C++0x</tag>
        <tag>智能指针</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[给VMWare Fusion设置固定IP]]></title>
    <url>%2F2016%2F10%2F15%2Fvmware-fusion-static-ip%2F</url>
    <content type="text"><![CDATA[最近在Mac上用WMware Fusion跑Linux，主要是用来做server端的开发，通过ssh连到虚拟机里做操作。 因为记性不好，我一般都会在/etc/hosts里设置一条记录，给虚拟机一个域名，像是这样 12# ubuntu虚拟机192.168.110.132 ubuntu.vm 然后我就可以通过域名的方式登录虚拟机了，像这样 1ssh up4dev@ubuntu.vm 但是使用的过程中遇到了一个问题，有时候虚拟机重启后发现虚拟机的IP发生了变化，这就导致了hosts的设置失效，必须重新设置hosts。 那么怎么能让虚机IP固定下来呢，Google了一圈下来，终于有了比较靠谱的方式，说起来还有点小麻烦，不过按照下面的步骤一条一条的来，应该都会成功。 先说下我的环境，macOS版本是10.12，VMware Fusion的版本是8.5.0。 步骤1 - 查询虚拟机的MAC地址话不多说，直接上图 步骤2 - 修改dhcpd.confdhcpd.conf位于目录/Library/Preferences/VMware Fusion/vmnet8。 用你最喜欢的文本编辑器打开/Library/Preferences/VMware Fusion/vmnet8/dhcpd.conf，我这里用vim，需要用管理员权限sudo 1sudo vim /Library/Preferences/VMware\ Fusion/vmnet8/dhcpd.conf 看到的内容大概是这样： 12345678910111213141516171819202122232425262728293031323334353637383940414243# Configuration file for ISC 2.0 vmnet-dhcpd operating on vmnet8.## This file was automatically generated by the VMware configuration program.# See Instructions below if you want to modify it.## We set domain-name-servers to make some DHCP clients happy# (dhclient as configured in SuSE, TurboLinux, etc.).# We also supply a domain name to make pump (Red Hat 6.x) happy.####### VMNET DHCP Configuration. Start of &quot;DO NOT MODIFY SECTION&quot; ###### Modification Instructions: This section of the configuration file contains# information generated by the configuration program. Do not modify this# section.# You are free to modify everything else. Also, this section must start# on a new line# This file will get backed up with a different name in the same directory# if this section is edited and you try to configure DHCP again.# Written at: 09/14/2016 14:21:31allow unknown-clients;default-lease-time 1800; # default is 30 minutesmax-lease-time 7200; # default is 2 hourssubnet 192.168.110.0 netmask 255.255.255.0 &#123; range 192.168.110.128 192.168.110.254; option broadcast-address 192.168.110.255; option domain-name-servers 192.168.110.2; option domain-name localdomain; default-lease-time 1800; # default is 30 minutes max-lease-time 7200; # default is 2 hours option netbios-name-servers 192.168.110.2; option routers 192.168.110.2;&#125;host vmnet8 &#123; hardware ethernet 00:50:56:C0:00:08; fixed-address 192.168.110.1; option domain-name-servers 0.0.0.0; option domain-name &quot;&quot;; option routers 0.0.0.0;&#125;####### VMNET DHCP Configuration. End of &quot;DO NOT MODIFY SECTION&quot; ####### 我们在这个文件的最后添加以下内容： 1234host Ubuntu16.04_0 &#123; hardware ethernet 00:0C:29:79:EC:1A; fixed-address 192.168.110.130;&#125; 有三行内容值得注意： 第1行，Ubuntu16.04_0是虚拟机的名字，看下图，注意要拼写要完全一致。 第2行，00:0C:29:79:EC:1A是上一步获取的MAC地址。 第3行，192.168.110.130是要设置的固定IP地址，注意要在虚拟机的IP网段，一般情况下就用上次虚拟机运行时的动态IP就可以了。 步骤3 - 重启VMWare Fusion必须重启VMWare Fusion才能使上边的设置生效。 步骤4 - 启动虚拟机此时在启动虚拟机，你会发现虚拟机的地址不会再变来变去了，永远是你在步骤2设置的固定IP。 参考 Set a Static IP Address in VMware Fusion 7]]></content>
      <categories>
        <category>泛技术</category>
      </categories>
      <tags>
        <tag>技术</tag>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用network create解决Docker容器互相连接的问题]]></title>
    <url>%2F2016%2F10%2F09%2Fdocker-network-create%2F</url>
    <content type="text"><![CDATA[目前在做一个P2P的程序，为了方便测试和部署，我们用docker来运行相同的程序实例。 作为一个P2P的程序，所有的实例之间应该是对等的，并且可以相互连接通信，看似简单，一开始的时候我们却在这里栽了跟头… 通常情况下，我们是通过在启动容器的时候传入--link参数的方式访问其他的容器的。 比如我们的一个容器要访问mysql，我们这样启动mysql(注意--name参数)： 1docker run -e MYSQL_ROOT_PASSWORD=password --name=mysql -d mysql 然后我们的需要访问mysql的容器这样启动(注意--link参数) 1docker run --name=my_container --link mysql:mysql my/my_image 这样，在我们新启动的容器my_container里就能够以域名mysql来访问mysql容器了。 可现在的情况是，作为一个P2P的程序，我们要启动两个容器(至少两个)container_a和container_b。希望container_a能访问container_b，并且container_b可以访问container_a，用跟上边同样的思路我们会想到这样启动 12docker run --name=container_a --link container_b:container_b -d my/my_imagedocker run --name=container_b --link container_a:container_a -d my/my_image 但是问题来了，当我们执行第一句命令时，docker会告诉我们，container_b不存在，可不是么，container_b此时还没有启动，当然是不存在的。这就造成了一种困境，container_a和container_b两者是相互依赖的，二者无论先启动谁，都要求先启动另一者，这种方式根本解决不了这个问题。 那么这种容器互相连接的问题怎么解决呢？就要轮到本文重点docker network create登场了。 首先我们先创建一个network 1docker network create my-net 通过执行命令可以查看到我们创建的网络 1docker network ls 结果应该类似下面这样 123cbd1aa22d04a bridge bridge local33be010f6cd9 host host local628c2540d5d3 my-net bridge local 我们看到my-net在这个列表中，然后我们就要利用这个新建的my-net网络来启动我们的容器。 12docker run --net=my-net --net-alias=container_a --name=container_a -d my/my_imagedocker run --net=my-net --net-alias=container_b --name=container_b -d my/my_image 我们通过--net参数指定容器使用的网络，通过--net-alias指定容器在这个网络中的别名，这样在这个网络中的所有的容器就都可以通过这个别名作为域名来访问到该容器了。]]></content>
      <categories>
        <category>泛技术</category>
      </categories>
      <tags>
        <tag>技术</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++11的智能指针(1) unique_ptr]]></title>
    <url>%2F2016%2F10%2F09%2Fcpp11-unique_ptr%2F</url>
    <content type="text"><![CDATA[C++11新引入了几种智能指针：unique_ptr，shared_ptr和weak_ptr，而原来的auto_ptr被弃用。 我会写几篇文章分别来介绍这几种智能指针的用法，本篇主要介绍unique_ptr。 主要介绍unique_ptr的两个主要特性: 保存对象的指针，当unique_ptr本身释放的时候，自动调用对象的析构函数。 唯一拥有它指向的对象，无法通过拷贝构造或者等号进行赋值。 我们先定义一个简单的类作为示例： 12345678910111213141516171819202122//test.h#include &lt;iostream&gt;class Test &#123;public: //标准构造函数 Test(int tag) : tag(tag) &#123; std::cout &lt;&lt; "Test::Test(int) " &lt;&lt; tag &lt;&lt; std::endl; &#125; //标准析构函数 ~Test() &#123; std::cout &lt;&lt; "Test::~Test() " &lt;&lt; tag &lt;&lt; std::endl; &#125; //测试输出 void test() &#123; std::cout &lt;&lt; "Test::test() " &lt;&lt; tag &lt;&lt; std::endl; &#125;private: int tag;&#125;; 特性1 - 保存对象的指针，当unique_ptr本身释放的时候，自动调用对象的析构函数这是一个智能指针的本分，让我们免去烦人又容易出错的new/delete操作。 示例1 - 最简单场景1234567891011//example1.cpp#include &lt;iostream&gt;#include &lt;memory&gt;#include "test.h"int main() &#123; std::unique_ptr&lt;Test&gt; p(new Test(1)); p-&gt;test(); return 0;&#125; 编译并执行 12g++ -o example1 -std=c++11 example1.cpp./example1 输出结果 123Test::Test(int) 1Test::test() 1Test::~Test() 1 基本不需要解释，我们看到我们并没有调用delete但是Test的析构函数还是被调用了。 示例2 - 有异常的场景12345678910111213141516171819202122232425262728//example2.cpp#include &lt;iostream&gt;#include &lt;memory&gt;#include &lt;string&gt;#include "test.h"int test(int tag) &#123; std::unique_ptr&lt;Test&gt; p(new Test(tag)); if (tag / 2) &#123; throw "except, tag = " + std::to_string(tag); //抛出异常 &#125; return tag;&#125;int main() &#123; try &#123; int ret = test(1); //不会抛出异常 std::cout &lt;&lt; "test(1) return " &lt;&lt; ret &lt;&lt; std::endl; ret = test(2); //会抛出异常 //因为上边的语句会抛出异常，下边这句不会被执行 std::cout &lt;&lt; "test(2) return " &lt;&lt; ret &lt;&lt; std::endl; &#125; catch (std::string e) &#123; //异常抛出是会执行 std::cout &lt;&lt; "exception caught: " &lt;&lt; e &lt;&lt; std::endl; &#125; return 0;&#125; 编译并执行 12g++ -o example2 -std=c++11 example2.cpp./example2 输出结果 123456Test::Test(int) 1Test::~Test() 1test(1) return 1Test::Test(int) 2Test::~Test() 2exception caught: except, tag = 2 第一次调用test(1)的时候，没有异常抛出，函数正常返回，我们看到函数返回前，Test的析构函数得到了调用。 第二次调用test(2)的时候，函数抛出了异常，要是普通指针的话，因为函数并没有正常结束，异常之后的语句就不再被调用，包括delete语句，就造成了内存泄漏。然而本例中我们看到即使异常抛出，Test的析构函数还是得到了调用，这就是智能指针的功劳。 特性2 - 唯一拥有它指向的对象，无法通过拷贝构造或者等号进行赋值。这个特性就是unique_ptr独有的特性了。 理解这个特性，需要结合C++11新引入的move语义，move语义不在本文的讨论范围，以后有精力我可能会写一篇关于move语义的文章，现在你想了解move语义的话可以参考这几篇文章： C++11新特性：右值引用与move语义 C++11 标准新特性: 右值引用与转移语义 [译]详解C++右值引用 我们看一下下边的代码 12345678910111213141516171819202122232425262728293031323334//example3.cpp#include &lt;iostream&gt;#include &lt;memory&gt;#include "test.h"void passTest(std::unique_ptr&lt;Test&gt; t) &#123; t-&gt;test();&#125;std::unique_ptr&lt;Test&gt; getPtr(int tag) &#123; std::unique_ptr&lt;Test&gt; p(new Test(tag)); return p;&#125;int main() &#123; std::unique_ptr&lt;Test&gt; p = std::unique_ptr&lt;Test&gt;(new Test(1)); //(0) p-&gt;test(); // std::unique_ptr&lt;Test&gt; p1 = p; //(1)编译失败 // std::unique_ptr&lt;Test&gt; p1(p); //(2)编译失败 std::unique_ptr&lt;Test&gt; p1 = std::move(p); //(3)编译通过 p1-&gt;test(); //(4)正确 // p-&gt;test(); //(5)错误，未定义行为 p = std::unique_ptr&lt;Test&gt;(new Test(2)); // passTest(p); //(6)编译失败 passTest(std::move(p)); //(7)编译通过 passTest(std::unique_ptr&lt;Test&gt;(new Test(3))); //(8)编译通过 p = getPtr(4); //(9)函数返回 return 0;&#125; 编译并执行 12g++ -o example3 -std=c++11 example3.cpp./example3 输出结果 12345678910Test::Test(int) 1Test::test() 1Test::test() 1Test::Test(int) 2Test::test() 2Test::~Test() 2Test::Test(int) 3Test::test() 3Test::~Test() 3Test::~Test() 1 这个例子主要是展示了unique_ptr的唯一性，也就是说unique_ptr唯一持有它指向的对象，无法通过赋值(1)或者拷贝构造(2)的方式进行初始化，它只能接受右值语义的参数来构造(0)(3)。 (4)(5)展示了move之后p已经失效。 (6)(7)(8)则展示了作为函数参数传递，同样要满足右值语义才可以。 (9)展示了作为函数返回值给unique_ptr赋值，这同样是满足右值语义的。 上边的这几个例子都说明了unique_ptr的唯一性，我们可以理解成任意时刻，只要你持有一个合法的unique_ptr，就可以保证你是唯一的一个持有人，不会出现另一个unique_ptr跟你相同的情况。]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>技术</tag>
        <tag>C++</tag>
        <tag>C++0x</tag>
        <tag>智能指针</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git修改提交记录的用户名和邮箱]]></title>
    <url>%2F2016%2F10%2F08%2Fgit-commit-user-modify%2F</url>
    <content type="text"><![CDATA[有时候，我们进行了一次commit之后发现，用户名和邮箱错了。为什么会有这种情况，往往我们在公司和个人的项目中，会使用不同的名称和邮箱，这样一来，电脑中就有了两套用户名和邮箱的配置，或者是公司的是默认，或者是个人的是默认的，但是开始一个新项目的时候，如果正好忘了修改项目的配置，就会出现提交用户不正确的情况。 一旦出现了这种情况的话，该怎么处理呢？ 如果这次提交是你的最后一次提交，那么很简单，通过下面的命令修改最后一次提交的用户名和邮箱地址： 1git commit --amend --author='yourname &lt;yourname@email.com&gt;' 如果已经推送到了远端服务器，通过下面的命令将修改强制推送到远端服务器就可以了： 1git push origin develop -f 参考文献 StackOverflow: Change commit author at one specific commit Git 基础 - 撤消操作]]></content>
      <categories>
        <category>泛技术</category>
      </categories>
      <tags>
        <tag>技术</tag>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[巧用Xcode的Target管理开发和生产的APP版本]]></title>
    <url>%2F2015%2F09%2F07%2Fuse-xcode-targets%2F</url>
    <content type="text"><![CDATA[APP开发过程中我们经常会碰到这样的情况：需要同时维护两个版本，一个是开发测试版本，一个是线上运行版本。两者需要有不同的Bundle ID，有时甚至要连接不同的服务器。 遇到这种情况，我们的做法往往是平时开发用测试版本的Bundle ID，测试的服务地址；上线的时候人工修改成正式版本的Bundle ID，线上的服务地址。 其实，Xcode的Target功能能够很好地解决这个问题。 我们新建一个项目来说明怎么做，项目的名字叫MultiTargetPrj。 Xcode默认给我们创建了两个Target，一个是MultiTargetPrj，另一个是MultiTargetPrjTests。MultiTargetPrjTests是单元测试的Target，我们暂且忽略。 我们用MultiTargetPrj作为正式版，在此基础上我们新建一个Target来做开发版应用。如下图，在已有的MultiTargetPrj Target上点击右键，在菜单中选择Duplicate。 这样Xcode就为我们创建了一个名为MultiTargetPrj copy的Target，如下图 后边带个copy尾巴的名字太不优雅了，让我们重命名一下，要重命名的地方不少，我们还是直接看图吧： 然后重命名Schemes： 最后然我们编辑一下info.plist，让应用在屏幕上显示的名字各不相同，正式版叫MT，开发版叫MT Dev，如下图所示： 我们在界面上放置一个label，预期在运行正式版的应用时，显示正式版，测试版的应用时，显示开发版。 为了让程序可以区分正式版和测试版，我们给开发版的target中设置一个预定义宏MULTITARGET_DEV: 然后我们用一段代码来区分版本，设置不同的版本的文字： 123456789- (void)viewDidLoad &#123; [super viewDidLoad]; // Do any additional setup after loading the view, typically from a nib.#ifndef MULTITARGET_DEV self.label.text = @"正式版";#else self.label.text = @"开发版";#endif&#125; 分别运行一次两个Target，我们看到的主屏是这样的： 两个Target的运行结果是这个样子的： 我把这个测试程序的代码放到了GitHub: andyzhshg/MultiTarget]]></content>
      <categories>
        <category>移动开发</category>
      </categories>
      <tags>
        <tag>技术</tag>
        <tag>iOS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[新的开始]]></title>
    <url>%2F2015%2F09%2F07%2Fnew-start%2F</url>
    <content type="text"><![CDATA[人啊，信誓旦旦说一些事情的时候是一回事，但是真正坚持做下去，却是另一回事。 写博客这件事，说了好几年，但是实际上这么多年下来，却几乎是没有写什么东西。 计划主要还是写一些技术相关的东西，算下来工作已经6年有余了，学了很多东西，但都称不上精通。杂七杂八，学了不知道多少种技术，最终混成了一个杂学家，也是有些惭愧呢。开这个博客，主要还是想借这个契机，整理和消化一些自己的所学，给自己的技术历程一个简单的记录，如果能够帮到误打误撞看到这些文章的人，也算是锦上添花了。 如果有闲情逸致呢，可能会把还能拿得出手的非技术的散文也发在这里，如果酸倒了诸位看客的牙齿，也非我故意，是你运气不好罢了。 这篇文章叫新的开始，但愿这次开始，是真正的开始，并坚持下去。]]></content>
      <categories>
        <category>杂</category>
      </categories>
      <tags>
        <tag>牢骚</tag>
        <tag>非技术</tag>
      </tags>
  </entry>
</search>